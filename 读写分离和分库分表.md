# 读写分离和分库分表

目前分库分表除了应用层基于业务逻辑的方式，在技术层面主要两种方式：一种是中间件代理，例如mycat和sharding-proxy，对于应用是比较透明的，支持的语言也多；第二种是侵入式，也就是数据库直连，例如sharding-jdbc。sharding-proxy和sharding-jdbc已经整合到sharding-Sphere里，官方文档：http://shardingsphere.apache.org/index_zh.html

数据的切分（Sharding）根据其切分规则的类型，可以分为两种切分模式。一种是按照不同的表（或者Schema）来切分到不同的数据库（主机）之上，这种切可以称之为数据的垂直（纵向）切分；另外一种则是根据表中的数据的逻辑关系，将同一个表中的数据按照某种条件拆分到多台数据库（主机）上面，这种切分称之为数据的水平（横向）切分。

## 1.mycat

### 1.1.mycat 读写分离

mycat环境均在docker中实现

参考:

[mariadb基于GTID主从复制搭建](https://github.com/AlphaYu/Adnc/tree/master/doc/mariadb)

[docker安装Mycat](https://github.com/MyCATApache/Mycat-Server/wiki/2.1-docker%E5%AE%89%E8%A3%85Mycat)

#### 1.1.1.配置mysql集群(一主一从)

由于只做测试，就不挂载目录了，配置文件到时候直接复制进去

##### 1.1.1.1.运行mysql container

```shell
# mysql-master
docker run -p 13311:3306 --restart=always --name mysql-master --network mynet --ip 172.10.0.11 -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7
# mysql-slave
docker run -p 13312:3306 --restart=always --name mysql-slave --network mynet --ip 172.10.0.12 -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7
```

##### 1.1.1.2.配置主库

复制配置文件出docker mysql-master

```shell
docker cp mysql-master:/etc/mysql/mysql.cnf C:\Program\MyDocker\mycat_mysql\mysql\master\mysql.cnf
```

编辑文件，修改my.cnf，在 [mysqld] 节点最后加上后保存:

```properties
[mysqld]
# 局域网内保证唯一 
server-id=11 
# bin日志，后缀 mysql-bin
log-bin=mysql-bin
```

> 注意：
>
> - log-bin=mysql-bin 使用binary logging，mysql-bin是log文件名的前缀；
> - server-id=1 唯一服务器ID，非0整数，不能和其他服务器的server-id重复；

复制配置文件进docker mysql-master

```shell
docker cp C:\Program\MyDocker\mycat_mysql\mysql\master\mysql.cnf mysql-master:/etc/mysql/mysql.cnf
```

重启 mysql 的docker , 让配置生效

```shell
docker restart mysql-master
```

##### 1.1.1.3.配置从库

配置mysql-slave

复制配置文件出docker mysql-slave

```shell
docker cp mysql-slave:/etc/mysql/mysql.cnf C:\Program\MyDocker\mycat_mysql\mysql\slave\mysql.cnf
```

编辑文件，修改my.cnf，在 [mysqld] 节点最后加上后保存:

```properties
[mysqld]
## 设置server_id,注意要唯一 
server-id=12
## 开启二进制日志功能，以备Slave作为其它Slave的Master时使用，如果不需要可不配置
log-bin=mysql-slave-bin 
## relay_log配置中继日志 
relay_log=edu-mysql-relay-bin
```

> 注意：
>
> - log-bin=mysql-bin 使用binary logging，mysql-bin是log文件名的前缀；
> - server-id=1 唯一服务器ID，非0整数，不能和其他服务器的server-id重复；

复制配置文件进docker mysql-slave

```shell
docker cp C:\Program\MyDocker\mycat_mysql\mysql\slave\mysql.cnf mysql-slave:/etc/mysql/mysql.cnf
```

重启 mysql 的docker , 让配置生效

```shell
docker restart mysql-slave
```

##### 1.1.1.4.配置同步复制

通过以下命令可以查看每个容器的ip

```shell
docker inspect --format='{{.NetworkSettings.IPAddress}}'  容器名称|容器id
```

登陆主mysql-master

```shell
docker exec -it mysql-master /bin/bash
## 登陆 mysql
## 在Master数据库创建数据同步用户，授予用户 slave REPLICATION SLAVE权限和REPLICATION CLIENT权限，用于在主从库之间同步数据。
mysql -u root -p123456

CREATE USER 'slave'@'%' IDENTIFIED BY '123456';
GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'slave'@'%';

## 注意 File 和 Position
show master status;

mysql> CREATE USER 'slave'@'%' IDENTIFIED BY '123456';
Query OK, 0 rows affected (0.02 sec)

mysql> GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'slave'@'%';
Query OK, 0 rows affected (0.02 sec)

mysql> show master status;
+------------------+----------+--------------+------------------+-------------------+
| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |
+------------------+----------+--------------+------------------+-------------------+
| mysql-bin.000001 |      617 |              |                  |                   |
+------------------+----------+--------------+------------------+-------------------+
1 row in set (0.00 sec)
```

登录mysql-slave , 注意 master_log_file 和 master_log_pos 对应上一步中的File 和 Position

```shell
docker exec -it mysql-slave /bin/bash
## 登陆 mysql
mysql -uroot -p123456
## 执行 
change master to master_host='172.10.0.11', master_user='slave', master_password='123456', master_port=3306, master_log_file='mysql-bin.000001', master_log_pos= 617, master_connect_retry=30;
```

> master_host ：Master的地址，指的是容器的独立ip 可以通过docker inspect --format=’{{.NetworkSettings.IPAddress}}’ 容器名称|容器id查询容器的ip
> master_port：Master的端口号，指的是容器的端口号
> master_user：用于数据同步的用户
> master_password：用于同步的用户的密码
> master_log_file：指定 Slave 从哪个日志文件开始复制数据，即上文中提到的 File 字段的值
> master_log_pos：从哪个 Position 开始读，即上文中提到的 Position 字段的值
> master_connect_retry：如果连接失败，重试的时间间隔，单位是秒，默认是60秒

在Slave 中的mysql终端执行 ，用于查看主从同步状态。

```sql
show slave status \G;
```

正常情况下，SlaveIORunning 和 SlaveSQLRunning 都是No，因为我们还没有开启主从复制过程。

开启主从复制过程

```sql
start slave;
```

然后再次查询主从同步状态

```sql
show slave status \G;
```

SlaveIORunning 和 SlaveSQLRunning 都是Yes，说明主从复制已经开启。

此时可以测试数据同步是否成功。

#### 1.1.2.配置mycat读写分离

##### 1.1.2.1.配置mycat文件

**主要配置server.xml,schema.xml,rule.xml等配置文件**

新建conf目录`C:\Program\MyDocker\mycat_mysql\mycat\conf`

**rule.xml基本不用修改**

**server.xml，修改mycat账户信息**

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE mycat:server SYSTEM "server.dtd">
<mycat:server xmlns:mycat="http://io.mycat/">

 <!-- 读写都可用的用户 -->
 <!-- mycat的账号 -->
 <!-- TESTDB 为逻辑数据库 对应schema.xml中 schema name="TESTDB" -->
	<user name="root" defaultAccount="true">
		<property name="password">mycat</property>
		<property name="schemas">TESTDB</property>
		<property name="defaultSchema">TESTDB</property>
		<!--No MyCAT Database selected 错误前会尝试使用该schema作为schema，不设置则为null,报错 -->
		
		<!-- 表级 DML 权限设置 -->
		<!-- 		
		<privileges check="false">
			<schema name="TESTDB" dml="0110" >
				<table name="tb01" dml="0000"></table>
				<table name="tb02" dml="1111"></table>
			</schema>
		</privileges>		
		 -->
	</user>
    
</mycat:server>
```

> 注意：
>
> - user标签是用来配置mycat的账号，无需跟数据库一致
> - 其中property name="schemas" 对应的shemas 是

**schema.xml，配置mysql主从信息。前提是根据上一节配置好一主一从，url对应的是上面查询的每个mysql容器的ip,注意对应关系即可：**

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE mycat:schema SYSTEM "schema.dtd">
<mycat:schema xmlns:mycat="http://io.mycat/">
    <!-- 配置逻辑库-->
    <!-- TESTDB 是mycat的逻辑库名称，链接需要用的 -->
    <schema name="TESTDB" checkSQLschema="false" sqlMaxLimit="100" dataNode="dn1"></schema>
    <!-- 逻辑库对应的真实数据库-->
    <!-- database 是MySQL数据库的库名 -->
    <dataNode name="dn1" dataHost="mycathost" database="mycat" />
    <!--
    dataNode节点中各属性说明：
    name：指定逻辑数据节点名称；
    dataHost：指定逻辑数据节点物理主机节点名称；
    database：指定物理主机节点上。如果一个节点上有多个库，可使用表达式db$0-99，     表示指定0-99这100个数据库；

    dataHost 节点中各属性说明：
        name：物理主机节点名称；
        maxCon：指定物理主机服务最大支持1000个连接；
        minCon：指定物理主机服务最小保持10个连接；
        writeType：指定写入类型；
            0，只在writeHost节点写入；
            1，在所有节点都写入。慎重开启，多节点写入顺序为默认写入根据配置顺序，第一个挂掉切换另一个；
        dbType：指定数据库类型；
        dbDriver：指定数据库驱动；
        balance：指定物理主机服务的负载模式。
            0，不开启读写分离机制；
            1，全部的readHost与stand by writeHost参与select语句的负载均衡，简单的说，当双主双从模式(M1->S1，M2->S2，并且M1与 M2互为主备)，正常情况下，M2,S1,S2都参与select语句的负载均衡；
            2，所有的readHost与writeHost都参与select语句的负载均衡，也就是说，当系统的写操作压力不大的情况下，所有主机都可以承担负载均衡；
-->
    
    
     <!--真实数据库所在的服务器地址 -->
    <dataHost name="mycathost" maxCon="1000" minCon="10" balance="3" writeType="0" dbType="mysql" dbDriver="native" switchType="1"  slaveThreshold="100">
        <heartbeat>select user()</heartbeat>
        <!-- 可以配置多个主库 -->
        <writeHost host="hostM1" url="172.10.0.11:3306"  user="root" password="123456">
            <!-- 可以配置多个从库 -->
            <readHost host="hostS2" url="172.10.0.12:3306"   user="root" password="123456" />
        </writeHost>
    </dataHost>
</mycat:schema>
```

> 注意：
>
> - schema 是用来配置 逻辑库的
> - dataNode 是用来配置 逻辑库对应的真实数据库
> - dataHost 是用来配置 真实数据库所在的服务器地址及数据库信息

##### 1.1.2.2.构建mycat image及container

在同级`C:\Program\MyDocker\mycat_mysql\mycat\`目录下创建Dockerfile文件

```dockerfile
FROM openjdk:8-jdk-stretch

# MAINTAINER: 维护者信息
MAINTAINER wyb

ADD http://dl.mycat.org.cn/1.6.7.6/20201126013625/Mycat-server-1.6.7.6-release-20201126013625-linux.tar.gz /usr/local
RUN cd /usr/local && tar -zxvf Mycat-server-1.6.7.6-release-20201126013625-linux.tar.gz && ls -lna

#容器数据卷，用于数据保存和持久化工作
#将mycat的配置文件的地址暴露出映射地址,启动时直接映射宿主机的文件夹

VOLUME /usr/local/mycat
WORKDIR /usr/local/mycat

#用来在构建镜像过程中设置环境变量
ENV MYCAT_HOME=/usr/local/mycat
ENV TZ Asia/Shanghai

#暴露出MyCat的所需端口
EXPOSE 8066 9066

#以前台进程的方式启动MyCat服务
CMD ["/usr/local/mycat/bin/mycat", "console","&"]
```

构建镜像

```shell
# 注意最后还有 .
docker build -t mycat-1.6.7.6 .
```

启动容器

```shell
#容器券：-v /usr/local/mycat/conf/:/usr/local/mycat/conf/
#冒号前是本机路径，冒号后是容器内的目录路径
#创建多个容器卷，尤其是配置文件和日志
docker run --restart=always --privileged=true --name mycat --network mynet --ip 172.10.0.10 -p 8066:8066 -p 9066:9066 -v C:\Program\MyDocker\mycat_mysql\mycat\conf\:/usr/local/mycat/conf/ -v C:\Program\MyDocker\mycat_mysql\mycat\logs\:/usr/local/mycat/logs/ -d mycat-1.6.7.6
```

#### 1.1.3.测试读写分离

从mycat进入数据，看下读写的操作情况

```shell
# 进入mysql-master容器
docker exec -it mysql-master /bin/bash
# 登录mycat,172.10.0.10 是指mycat容器的Ip地址，如果容器没有指定固定Ip，你的可能不一样，请注意。
mysql -uroot -pmycat -P8066 -h172.10.0.10
mysql -uroot -pmycat -P8066 -hmycat
# 显示所有数据库
show databases;
# 多次执行下面的sql,观察hostname的变化。
select @@hostname;
```

执行日志

```shell
mysql> show databases;
+----------+
| DATABASE |
+----------+
| TESTDB   |
+----------+
1 row in set (0.01 sec)

mysql> select @@hostname;
+--------------+
| @@hostname   |
+--------------+
| 880d22044887 |
+--------------+
1 row in set (0.10 sec)

mysql> use TESTDB;
Database changed
mysql> show tables ;
Empty set (0.00 sec)

### test 在 mysql-master中创建
mysql> show tables ;
+-----------------+
| Tables_in_mycat |
+-----------------+
| test            |
+-----------------+
1 row in set (0.00 sec)

### test_write 在 mycat中创建
mysql> create table test_write as select * from test;
Query OK, 1 row affected (0.05 sec)
Records: 1  Duplicates: 0  Warnings: 0

mysql> show tables;
+-----------------+
| Tables_in_mycat |
+-----------------+
| test            |
| test_write      |
+-----------------+
2 rows in set (0.00 sec)

```

### 1.2.mycat分库分表

在不考虑读写分离的情况下，只测试分库分表功能

#### 1.2.1.配置2个单独的mysql

#### 1.2.2.重新配置mycat

#### 1.2.3.测试分库分表



## 2.sharding-jdbc

### 2.1.读写分离

#### 2.1.1.新建springboot项目sharding-jdbc

##### 2.1.1.1.项目pom

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>
	<parent>
		<groupId>org.springframework.boot</groupId>
		<artifactId>spring-boot-starter-parent</artifactId>
		<version>2.4.5</version>
		<relativePath/> <!-- lookup parent from repository -->
	</parent>
	<groupId>com.wyb</groupId>
	<artifactId>sharding-jdbc</artifactId>
	<version>0.0.1-SNAPSHOT</version>
	<name>sharding-jdbc</name>
	<description>Demo project for Spring Boot</description>
	<properties>
		<java.version>1.8</java.version>
		<sharding-sphere.version>4.0.0-RC1</sharding-sphere.version>
	</properties>
	<dependencies>
		<!-- 依赖web -->
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-web</artifactId>
		</dependency>
		<!-- 依赖mybatis -->
		<dependency>
			<groupId>org.mybatis.spring.boot</groupId>
			<artifactId>mybatis-spring-boot-starter</artifactId>
			<version>2.1.4</version>
		</dependency>
		<!-- 依赖mysql -->
		<!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java -->
		<dependency>
			<groupId>mysql</groupId>
			<artifactId>mysql-connector-java</artifactId>
			<scope>runtime</scope>
		</dependency>


		<!-- 依赖shardingsphere -->
		<!-- https://mvnrepository.com/artifact/org.apache.shardingsphere/sharding-core-common -->
		<dependency>
			<groupId>org.apache.shardingsphere</groupId>
			<artifactId>sharding-core-common</artifactId>
			<version>${sharding-sphere.version}</version>
		</dependency>
        <dependency>
            <groupId>org.apache.shardingsphere</groupId>
            <artifactId>sharding-jdbc-spring-boot-starter</artifactId>
            <version>${sharding-sphere.version}</version>
        </dependency>
		<dependency>
			<groupId>com.alibaba</groupId>
			<artifactId>druid-spring-boot-starter</artifactId>
			<version>1.1.21</version>
		</dependency>

		<dependency>
			<groupId>org.projectlombok</groupId>
			<artifactId>lombok</artifactId>
			<optional>true</optional>
		</dependency>
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-test</artifactId>
			<scope>test</scope>
		</dependency>
	</dependencies>

	<build>
		<plugins>
			<plugin>
				<groupId>org.springframework.boot</groupId>
				<artifactId>spring-boot-maven-plugin</artifactId>
				<configuration>
					<excludes>
						<exclude>
							<groupId>org.projectlombok</groupId>
							<artifactId>lombok</artifactId>
						</exclude>
					</excludes>
				</configuration>
			</plugin>
		</plugins>
	</build>

</project>

```

##### 2.1.1.2.配置application.yaml

```yml
server:
  port: 8085
spring:
  main:
    allow-bean-definition-overriding: true
  shardingsphere:
    # 参数配置，显示sql
    props:
      sql:
        show: true
    # 配置数据源
    datasource:
      # 给每个数据源取别名，下面 的ds1,ds2,ds3
      names: ds1,ds2,ds3
      # 给master ds1配置数据库连接信息
      ds1:
        # 配置druid数据库源
        type: com.alibaba.druid.pool.DruidDataSource
        driver-class-name: com.mysql.cj.jdbc.Driver
        url: jdbc:mysql://localhost:13311/ksd_shading_db?useUnicode=true&characterEncoding=utf8
        username: root
        password: 123456
        maxPoolSize: 100
        minPoolSize: 5
      # 配置slave
      ds2:
        # 配置druid数据库源
        type: com.alibaba.druid.pool.DruidDataSource
        driver-class-name: com.mysql.cj.jdbc.Driver
        url: jdbc:mysql://localhost:13312/ksd_shading_db?useUnicode=true&characterEncoding=utf8
        username: root
        password: 123456
        maxPoolSize: 100
        minPoolSize: 5
      ds3:
        # 配置druid数据库源
        type: com.alibaba.druid.pool.DruidDataSource
        driver-class-name: com.mysql.cj.jdbc.Driver
        url: jdbc:mysql://localhost:13312/ksd_shading_db?useUnicode=true&characterEncoding=utf8
        username: root
        password: 123456
        maxPoolSize: 100
        minPoolSize: 5
    # 配置sharding
    sharding:
      # 默认数据源，主要有哦那个与写，注意一定要配置读写分离
      # 如果不配置，那就会把所有节点都当作slave节点
      default-data-source-name: ds1
      # 配置分表的规则
      tables:
        # ksd_user 逻辑表名
        ksd_user:
          # 数据节点：数据源$->{0..N}.逻辑表名$->{0..N}
          actual-data-nodes: ds$->{0..1}.ksd_user$->{0..1}
          # 拆分库策略
          database-strategy:
            standard:
              shardingColumn: birthday
              preciseAlgorithmClassName: com.wyb.shardingjdbc.config.BirthdayAlgorithm
          # 分表策略
          table-strategy:
            inline:
              # 分片字段
              sharding-column: age
              # 分片算法表达式
              algorithm-expression: ksd_user$->{age % 2}
    # 配置数据源的读写分离，但是数据库意义的那个要做主从复制
    masterslave:
      # 配置主从名称，可以去任何名字
      name: ms
      # 配置主库master,负责写入
      master-data-source-name: ds1
      # 配置从库slave,负责写入
      slave-data-source-names: ds2,ds3
      # 配置slave节点的负载均衡策略，采用轮询机制
      load-balance-algorithm-type: round_robin
# 整合mybtis的配置
mybatis:
  mapper-locations: classpath:mapper/*.xml
  type-aliases-package: com.wyb.shardingjdbc.entity
debug: false
```

##### 2.1.1.3.新建UserMapper

```java
package com.wyb.shardingjdbc.mapper;

import com.wyb.shardingjdbc.entity.User;
import org.apache.ibatis.annotations.Insert;
import org.apache.ibatis.annotations.Mapper;
import org.apache.ibatis.annotations.Select;
import org.springframework.stereotype.Repository;
import org.springframework.stereotype.Service;

import java.util.List;

@Mapper
public interface UserMapper {
    @Insert("insert into ksd_user(nickname,password,age,sex,birthday) values(#{nickname},#{password},#{age},#{sex},#{birthday})")
    void addUser(User user);

    @Select("select * from ksd_user")
    List<User> findUsers();
}

```

##### 2.1.1.4.新建实体类User

```java
package com.wyb.shardingjdbc.entity;


import lombok.Data;

import java.util.Date;

@Data
public class User {
    // 主键
    private Long id;
    // 用户名
    private String nickname;
    // 密码
    private String password;
    // 年龄
    private Integer age;
    /**
     * 性别 0代表男 1代表女
     */
    private Integer sex;

    private Date birthday;
}

```

##### 2.1.1.5.新建UserController

```java
package com.wyb.shardingjdbc.controller;

import com.wyb.shardingjdbc.entity.User;
import com.wyb.shardingjdbc.mapper.UserMapper;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

import javax.annotation.Resource;
import java.text.ParseException;
import java.text.SimpleDateFormat;
import java.util.Date;
import java.util.List;
import java.util.Random;

@RestController
@RequestMapping("/user")
public class UserController  {
    @Autowired
    private UserMapper userMapper;

    @GetMapping("/save")
    public String insert() throws ParseException {
        User user = new User();
        user.setNickname("user_" + new Random().nextInt());
        user.setPassword("12345" );
        user.setAge(new Random().nextInt(80));
        user.setSex(new Random().nextInt(1));
        SimpleDateFormat simpleDateFormat = new SimpleDateFormat("yyyy-MM-dd");//注意月份是MM
        Date date = simpleDateFormat.parse("1988-12-03");
        user.setBirthday(date);
        userMapper.addUser(user);
        return "success";
    }
    @GetMapping("/listuser")
    public List<User> listuser() {
        return userMapper.findUsers();
    }
}

```

>  注意:
>
> @Autowired那里会报错
>
> ```shell
> Description:
> 
> Field userEntityMapper in com.xxx.xxx.service.UserService required a bean of type 'com.xxx.xxx.dao.UserEntityMapper' that could not be found.
> 
> Action:
> 
> Consider defining a bean of type 'com.xxx.xxx.dao.UserEntityMapper' in your configuration.
> ```
>
> 解决方式：
>
> 1.检查自己写的注解是否错了，并没有。
>
> 2.在网上查找解决方式：如下所示：
>
> 步骤一：
>
> 　　在springboot的配置文件添加，mybatis的配置如下所示：
>
> ```
> mybatis:
>   typeAliasesPackage: com.xxx.xxx.dao.entity
>   mapperLocations: classpath:mapper/*.xml
> ```
>
>  步骤二：
>
> 　　①将接口与对应的实现类放在与application启动类的同一个目录或者他的子目录下，这样注解可以被扫描到，这是最省事的办法。（没测试）
> 　　②或者在启动类上加上@MapperScan或者@ComponentScan注解，手动指定application类要扫描哪些包下的注解，如下所示： 
>
> ```
> @SpringBootApplication
> @ComponentScan(basePackages = {"com.xxx.xxx.dao"})
> ```
>
> 　　③或者在接口上添加@Mapper注解。
>
> ```
> @Mapper
> public interface UserMapper {
> }
> 
> ```
>
> ps：之所以没有找到对应的Bean是因为，@SpringBootApplication没有扫描到。

#### 2.1.2.测试

##### 2.1.2.1.插入用户

```
http://localhost:8085/user/save
```

查看console

```shell
2021-05-08 18:22:39.847  INFO 3420 --- [           main] com.alibaba.druid.pool.DruidDataSource   : {dataSource-1} inited
2021-05-08 18:22:40.544  INFO 3420 --- [           main] com.alibaba.druid.pool.DruidDataSource   : {dataSource-2} inited
2021-05-08 18:22:40.582  INFO 3420 --- [           main] com.alibaba.druid.pool.DruidDataSource   : {dataSource-3} inited
2021-05-08 18:22:40.858  INFO 3420 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2021-05-08 18:22:41.044  INFO 3420 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8085 (http) with context path ''
2021-05-08 18:22:41.053  INFO 3420 --- [           main] c.w.s.ShardingJdbcApplication            : Started ShardingJdbcApplication in 3.442 seconds (JVM running for 4.4)
2021-05-08 18:22:51.013  INFO 3420 --- [nio-8085-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
2021-05-08 18:22:51.013  INFO 3420 --- [nio-8085-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
2021-05-08 18:22:51.014  INFO 3420 --- [nio-8085-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 1 ms
2021-05-08 18:22:51.075  INFO 3420 --- [nio-8085-exec-1] ShardingSphere-SQL                       : Rule Type: master-slave
2021-05-08 18:22:51.076  INFO 3420 --- [nio-8085-exec-1] ShardingSphere-SQL                       : SQL: insert into ksd_user(nickname,password,age,sex,birthday) values(?,?,?,?,?) ::: DataSources: ds1
```

插入的数据库为ds1

```shell
SQL: insert into ksd_user(nickname,password,age,sex,birthday) values(?,?,?,?,?) ::: DataSources: ds1
```

##### 2.1.2.2.查看用户

```
http://localhost:8085/user/listuser
```

查看console

```shell
2021-05-08 18:23:48.960  INFO 3420 --- [nio-8085-exec-3] ShardingSphere-SQL                       : Rule Type: master-slave
2021-05-08 18:23:48.960  INFO 3420 --- [nio-8085-exec-3] ShardingSphere-SQL                       : SQL: select * from ksd_user ::: DataSources: ds2
2021-05-08 18:23:57.000  INFO 3420 --- [nio-8085-exec-7] ShardingSphere-SQL                       : Rule Type: master-slave
2021-05-08 18:23:57.000  INFO 3420 --- [nio-8085-exec-7] ShardingSphere-SQL                       : SQL: select * from ksd_user ::: DataSources: ds3
```

看见两次查询的数据库都是不同的，因为采取的是轮询模式

```shell
## 第一次查询
SQL: select * from ksd_user ::: DataSources: ds2
## 第二次查询
SQL: select * from ksd_user ::: DataSources: ds3
```

### 2.2.分库分表