# 读写分离和分库分表

目前分库分表除了应用层基于业务逻辑的方式，在技术层面主要两种方式：一种是中间件代理，例如mycat和sharding-proxy，对于应用是比较透明的，支持的语言也多；第二种是侵入式，也就是数据库直连，例如sharding-jdbc。sharding-proxy和sharding-jdbc已经整合到sharding-Sphere里，官方文档：http://shardingsphere.apache.org/index_zh.html

数据的切分（Sharding）根据其切分规则的类型，可以分为两种切分模式。一种是按照不同的表（或者Schema）来切分到不同的数据库（主机）之上，这种切可以称之为数据的垂直（纵向）切分；另外一种则是根据表中的数据的逻辑关系，将同一个表中的数据按照某种条件拆分到多台数据库（主机）上面，这种切分称之为数据的水平（横向）切分。

## 1.mycat

### 1.1.mycat 读写分离

mycat环境均在docker中实现

参考:

[mariadb基于GTID主从复制搭建](https://github.com/AlphaYu/Adnc/tree/master/doc/mariadb)

[docker安装Mycat](https://github.com/MyCATApache/Mycat-Server/wiki/2.1-docker%E5%AE%89%E8%A3%85Mycat)

#### 1.1.1.配置mysql集群(一主一从)

由于只做测试，就不挂载目录了，配置文件到时候直接复制进去

##### 1.1.1.1.运行mysql container

```shell
# 创建mynet
docker network create --driver bridge --subnet 172.10.0.0/16 --gateway 172.10.0.1 mynet

# mysql-master
docker run -p 13311:3306 --name mysql-master --network mynet --ip 172.10.0.11 -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7
# mysql-slave
docker run -p 13312:3306 --name mysql-slave --network mynet --ip 172.10.0.12 -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7
# mysql-slave-1
docker run -p 13313:3306 --name mysql-slave-1 --network mynet --ip 172.10.0.13 -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7
```

##### 1.1.1.2.配置主库

复制配置文件出docker mysql-master

```shell
docker cp mysql-master:/etc/mysql/mysql.cnf C:\Program\MyDocker\mycat_mysql\mysql\master\mysql.cnf
```

编辑文件，修改my.cnf，在 [mysqld] 节点最后加上后保存:

```properties
[mysqld]
# 局域网内保证唯一 
server-id=11 
# bin日志，后缀 mysql-bin
log-bin=mysql-bin
```

> 注意：
>
> - log-bin=mysql-bin 使用binary logging，mysql-bin是log文件名的前缀；
> - server-id=1 唯一服务器ID，非0整数，不能和其他服务器的server-id重复；

复制配置文件进docker mysql-master

```shell
docker cp C:\Program\MyDocker\mycat_mysql\mysql\master\mysql.cnf mysql-master:/etc/mysql/mysql.cnf
```

重启 mysql 的docker , 让配置生效

```shell
docker restart mysql-master
```

##### 1.1.1.3.配置从库

配置mysql-slave

复制配置文件出docker mysql-slave

```shell
docker cp mysql-slave:/etc/mysql/mysql.cnf C:\Program\MyDocker\mycat_mysql\mysql\slave\mysql.cnf
```

编辑文件，修改my.cnf，在 [mysqld] 节点最后加上后保存:

```properties
[mysqld]
## 设置server_id,注意要唯一 
server-id=12
## 开启二进制日志功能，以备Slave作为其它Slave的Master时使用，如果不需要可不配置
log-bin=mysql-slave-bin 
## relay_log配置中继日志 
relay_log=edu-mysql-relay-bin
```

> 注意：
>
> - log-bin=mysql-bin 使用binary logging，mysql-bin是log文件名的前缀；
> - server-id=1 唯一服务器ID，非0整数，不能和其他服务器的server-id重复；

复制配置文件进docker mysql-slave

```shell
docker cp C:\Program\MyDocker\mycat_mysql\mysql\slave\mysql.cnf mysql-slave:/etc/mysql/mysql.cnf
```

重启 mysql 的docker , 让配置生效

```shell
docker restart mysql-slave
```

##### 1.1.1.4.配置同步复制

通过以下命令可以查看每个容器的ip

```shell
docker inspect --format='{{.NetworkSettings.IPAddress}}'  容器名称|容器id
```

登陆主mysql-master

```shell
docker exec -it mysql-master /bin/bash
## 登陆 mysql
## 在Master数据库创建数据同步用户，授予用户 slave REPLICATION SLAVE权限和REPLICATION CLIENT权限，用于在主从库之间同步数据。
mysql -u root -p123456

CREATE USER 'slave'@'%' IDENTIFIED BY '123456';
GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'slave'@'%';

## 注意 File 和 Position
show master status;

mysql> CREATE USER 'slave'@'%' IDENTIFIED BY '123456';
Query OK, 0 rows affected (0.02 sec)

mysql> GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'slave'@'%';
Query OK, 0 rows affected (0.02 sec)

mysql> show master status;
+------------------+----------+--------------+------------------+-------------------+
| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |
+------------------+----------+--------------+------------------+-------------------+
| mysql-bin.000001 |      617 |              |                  |                   |
+------------------+----------+--------------+------------------+-------------------+
1 row in set (0.00 sec)
```

登录mysql-slave , 注意 master_log_file 和 master_log_pos 对应上一步中的File 和 Position

```shell
docker exec -it mysql-slave /bin/bash
## 登陆 mysql
mysql -uroot -p123456
## 执行 
change master to master_host='172.10.0.11', master_user='slave', master_password='123456', master_port=3306, master_log_file='mysql-bin.000001', master_log_pos= 617, master_connect_retry=30;
```

> master_host ：Master的地址，指的是容器的独立ip 可以通过docker inspect --format=’{{.NetworkSettings.IPAddress}}’ 容器名称|容器id查询容器的ip
> master_port：Master的端口号，指的是容器的端口号
> master_user：用于数据同步的用户
> master_password：用于同步的用户的密码
> master_log_file：指定 Slave 从哪个日志文件开始复制数据，即上文中提到的 File 字段的值
> master_log_pos：从哪个 Position 开始读，即上文中提到的 Position 字段的值
> master_connect_retry：如果连接失败，重试的时间间隔，单位是秒，默认是60秒

在Slave 中的mysql终端执行 ，用于查看主从同步状态。

```sql
show slave status \G;
```

正常情况下，SlaveIORunning 和 SlaveSQLRunning 都是No，因为我们还没有开启主从复制过程。

开启主从复制过程

```sql
start slave;
```

然后再次查询主从同步状态

```sql
show slave status \G;
```

SlaveIORunning 和 SlaveSQLRunning 都是Yes，说明主从复制已经开启。

此时可以测试数据同步是否成功。

#### 1.1.2.配置mycat读写分离

##### 1.1.2.1.配置mycat文件

**主要配置server.xml,schema.xml,rule.xml等配置文件**

新建conf目录`C:\Program\MyDocker\mycat_mysql\mycat\conf`

**rule.xml基本不用修改**

**server.xml，修改mycat账户信息**

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE mycat:server SYSTEM "server.dtd">
<mycat:server xmlns:mycat="http://io.mycat/">

 <!-- 读写都可用的用户 -->
 <!-- mycat的账号 -->
 <!-- TESTDB 为逻辑数据库 对应schema.xml中 schema name="TESTDB" -->
	<user name="root" defaultAccount="true">
		<property name="password">mycat</property>
		<property name="schemas">TESTDB</property>
		<property name="defaultSchema">TESTDB</property>
		<!--No MyCAT Database selected 错误前会尝试使用该schema作为schema，不设置则为null,报错 -->
		
		<!-- 表级 DML 权限设置 -->
		<!-- 		
		<privileges check="false">
			<schema name="TESTDB" dml="0110" >
				<table name="tb01" dml="0000"></table>
				<table name="tb02" dml="1111"></table>
			</schema>
		</privileges>		
		 -->
	</user>
    
</mycat:server>
```

> 注意：
>
> - user标签是用来配置mycat的账号，无需跟数据库一致
> - 其中property name="schemas" 对应的shemas 是

**schema.xml，配置mysql主从信息。前提是根据上一节配置好一主一从，url对应的是上面查询的每个mysql容器的ip,注意对应关系即可：**

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE mycat:schema SYSTEM "schema.dtd">
<mycat:schema xmlns:mycat="http://io.mycat/">
    <!-- 配置逻辑库-->
    <!-- TESTDB 是mycat的逻辑库名称，链接需要用的 -->
    <schema name="TESTDB" checkSQLschema="false" sqlMaxLimit="100" dataNode="dn1"></schema>
    <!-- 逻辑库对应的真实数据库-->
    <!-- database 是MySQL数据库的库名 -->
    <dataNode name="dn1" dataHost="mycathost" database="mycat" />
    <!--
    dataNode节点中各属性说明：
    name：指定逻辑数据节点名称；
    dataHost：指定逻辑数据节点物理主机节点名称；
    database：指定物理主机节点上。如果一个节点上有多个库，可使用表达式db$0-99，     表示指定0-99这100个数据库；

    dataHost 节点中各属性说明：
        name：物理主机节点名称；
        maxCon：指定物理主机服务最大支持1000个连接；
        minCon：指定物理主机服务最小保持10个连接；
        writeType：指定写入类型；
            0，只在writeHost节点写入；
            1，在所有节点都写入。慎重开启，多节点写入顺序为默认写入根据配置顺序，第一个挂掉切换另一个；
        dbType：指定数据库类型；
        dbDriver：指定数据库驱动；
        balance：指定物理主机服务的负载模式。
            0，不开启读写分离机制；
            1，全部的readHost与stand by writeHost参与select语句的负载均衡，简单的说，当双主双从模式(M1->S1，M2->S2，并且M1与 M2互为主备)，正常情况下，M2,S1,S2都参与select语句的负载均衡；
            2，所有的readHost与writeHost都参与select语句的负载均衡，也就是说，当系统的写操作压力不大的情况下，所有主机都可以承担负载均衡；
-->
    
    
     <!--真实数据库所在的服务器地址 -->
    <dataHost name="mycathost" maxCon="1000" minCon="10" balance="3" writeType="0" dbType="mysql" dbDriver="native" switchType="1"  slaveThreshold="100">
        <heartbeat>select user()</heartbeat>
        <!-- 可以配置多个主库 -->
        <writeHost host="hostM1" url="172.10.0.11:3306"  user="root" password="123456">
            <!-- 可以配置多个从库 -->
            <readHost host="hostS2" url="172.10.0.12:3306"   user="root" password="123456" />
        </writeHost>
    </dataHost>
</mycat:schema>
```

> 注意：
>
> - schema 是用来配置 逻辑库的
> - dataNode 是用来配置 逻辑库对应的真实数据库
> - dataHost 是用来配置 真实数据库所在的服务器地址及数据库信息

##### 1.1.2.2.构建mycat image及container

在同级`C:\Program\MyDocker\mycat_mysql\mycat\`目录下创建Dockerfile文件

```dockerfile
FROM openjdk:8-jdk-stretch

# MAINTAINER: 维护者信息
MAINTAINER wyb

ADD http://dl.mycat.org.cn/1.6.7.6/20201126013625/Mycat-server-1.6.7.6-release-20201126013625-linux.tar.gz /usr/local
RUN cd /usr/local && tar -zxvf Mycat-server-1.6.7.6-release-20201126013625-linux.tar.gz && ls -lna

#容器数据卷，用于数据保存和持久化工作
#将mycat的配置文件的地址暴露出映射地址,启动时直接映射宿主机的文件夹

VOLUME /usr/local/mycat
WORKDIR /usr/local/mycat

#用来在构建镜像过程中设置环境变量
ENV MYCAT_HOME=/usr/local/mycat
ENV TZ Asia/Shanghai

#暴露出MyCat的所需端口
EXPOSE 8066 9066

#以前台进程的方式启动MyCat服务
CMD ["/usr/local/mycat/bin/mycat", "console","&"]
```

构建镜像

```shell
# 注意最后还有 .
docker build -t mycat-1.6.7.6 .
```

启动容器

```shell
#容器券：-v /usr/local/mycat/conf/:/usr/local/mycat/conf/
#冒号前是本机路径，冒号后是容器内的目录路径
#创建多个容器卷，尤其是配置文件和日志
docker run --restart=always --privileged=true --name mycat --network mynet --ip 172.10.0.10 -p 8066:8066 -p 9066:9066 -v C:\Program\MyDocker\mycat_mysql\mycat\conf\:/usr/local/mycat/conf/ -v C:\Program\MyDocker\mycat_mysql\mycat\logs\:/usr/local/mycat/logs/ -d mycat-1.6.7.6
```

#### 1.1.3.测试读写分离

从mycat进入数据，看下读写的操作情况

```shell
# 进入mysql-master容器
docker exec -it mysql-master /bin/bash
# 登录mycat,172.10.0.10 是指mycat容器的Ip地址，如果容器没有指定固定Ip，你的可能不一样，请注意。
mysql -uroot -pmycat -P8066 -h172.10.0.10
mysql -uroot -pmycat -P8066 -hmycat
# 显示所有数据库
show databases;
# 多次执行下面的sql,观察hostname的变化。
select @@hostname;
```

执行日志

```shell
mysql> show databases;
+----------+
| DATABASE |
+----------+
| TESTDB   |
+----------+
1 row in set (0.01 sec)

mysql> select @@hostname;
+--------------+
| @@hostname   |
+--------------+
| 880d22044887 |
+--------------+
1 row in set (0.10 sec)

mysql> use TESTDB;
Database changed
mysql> show tables ;
Empty set (0.00 sec)

### test 在 mysql-master中创建
mysql> show tables ;
+-----------------+
| Tables_in_mycat |
+-----------------+
| test            |
+-----------------+
1 row in set (0.00 sec)

### test_write 在 mycat中创建
mysql> create table test_write as select * from test;
Query OK, 1 row affected (0.05 sec)
Records: 1  Duplicates: 0  Warnings: 0

mysql> show tables;
+-----------------+
| Tables_in_mycat |
+-----------------+
| test            |
| test_write      |
+-----------------+
2 rows in set (0.00 sec)

```

### 1.2.mycat分库分表

在不考虑读写分离的情况下，只测试分库分表功能

#### 1.2.1.配置2个单独的mysql

#### 1.2.2.重新配置mycat

#### 1.2.3.测试分库分表



## 2.sharding-jdbc

### 2.1.读写分离

#### 2.1.1.新建springboot项目sharding-jdbc

##### 2.1.1.1.项目pom

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>
	<parent>
		<groupId>org.springframework.boot</groupId>
		<artifactId>spring-boot-starter-parent</artifactId>
		<version>2.4.5</version>
		<relativePath/> <!-- lookup parent from repository -->
	</parent>
	<groupId>com.wyb</groupId>
	<artifactId>sharding-jdbc</artifactId>
	<version>0.0.1-SNAPSHOT</version>
	<name>sharding-jdbc</name>
	<description>Demo project for Spring Boot</description>
	<properties>
		<java.version>1.8</java.version>
		<sharding-sphere.version>4.0.0-RC1</sharding-sphere.version>
	</properties>
	<dependencies>
		<!-- 依赖web -->
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-web</artifactId>
		</dependency>
		<!-- 依赖mybatis -->
		<dependency>
			<groupId>org.mybatis.spring.boot</groupId>
			<artifactId>mybatis-spring-boot-starter</artifactId>
			<version>2.1.4</version>
		</dependency>
		<!-- 依赖mysql -->
		<!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java -->
		<dependency>
			<groupId>mysql</groupId>
			<artifactId>mysql-connector-java</artifactId>
			<scope>runtime</scope>
		</dependency>


		<!-- 依赖shardingsphere -->
		<!-- https://mvnrepository.com/artifact/org.apache.shardingsphere/sharding-core-common -->
		<dependency>
			<groupId>org.apache.shardingsphere</groupId>
			<artifactId>sharding-core-common</artifactId>
			<version>${sharding-sphere.version}</version>
		</dependency>
        <dependency>
            <groupId>org.apache.shardingsphere</groupId>
            <artifactId>sharding-jdbc-spring-boot-starter</artifactId>
            <version>${sharding-sphere.version}</version>
        </dependency>
		<dependency>
			<groupId>com.alibaba</groupId>
			<artifactId>druid-spring-boot-starter</artifactId>
			<version>1.1.21</version>
		</dependency>

		<dependency>
			<groupId>org.projectlombok</groupId>
			<artifactId>lombok</artifactId>
			<optional>true</optional>
		</dependency>
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-test</artifactId>
			<scope>test</scope>
		</dependency>
	</dependencies>

	<build>
		<plugins>
			<plugin>
				<groupId>org.springframework.boot</groupId>
				<artifactId>spring-boot-maven-plugin</artifactId>
				<configuration>
					<excludes>
						<exclude>
							<groupId>org.projectlombok</groupId>
							<artifactId>lombok</artifactId>
						</exclude>
					</excludes>
				</configuration>
			</plugin>
		</plugins>
	</build>

</project>

```

##### 2.1.1.2.配置application.yaml

```yml
server:
  port: 8085
spring:
  main:
    allow-bean-definition-overriding: true
  shardingsphere:
    # 参数配置，显示sql
    props:
      sql:
        show: true
    # 配置数据源
    datasource:
      # 给每个数据源取别名，下面 的ds1,ds2,ds3
      names: ds1,ds2,ds3
      # 给master ds1配置数据库连接信息
      ds1:
        # 配置druid数据库源
        type: com.alibaba.druid.pool.DruidDataSource
        driver-class-name: com.mysql.cj.jdbc.Driver
        url: jdbc:mysql://localhost:13311/ksd_shading_db?useUnicode=true&characterEncoding=utf8
        username: root
        password: 123456
        maxPoolSize: 100
        minPoolSize: 5
      # 配置slave
      ds2:
        # 配置druid数据库源
        type: com.alibaba.druid.pool.DruidDataSource
        driver-class-name: com.mysql.cj.jdbc.Driver
        url: jdbc:mysql://localhost:13312/ksd_shading_db?useUnicode=true&characterEncoding=utf8
        username: root
        password: 123456
        maxPoolSize: 100
        minPoolSize: 5
      ds3:
        # 配置druid数据库源
        type: com.alibaba.druid.pool.DruidDataSource
        driver-class-name: com.mysql.cj.jdbc.Driver
        url: jdbc:mysql://localhost:13312/ksd_shading_db?useUnicode=true&characterEncoding=utf8
        username: root
        password: 123456
        maxPoolSize: 100
        minPoolSize: 5
    # 配置sharding
    sharding:
      # 默认数据源，主要有哦那个与写，注意一定要配置读写分离
      # 如果不配置，那就会把所有节点都当作slave节点
      default-data-source-name: ds1
      # 配置分表的规则
      tables:
        # ksd_user 逻辑表名
        ksd_user:
          # 数据节点：数据源$->{0..N}.逻辑表名$->{0..N}
          actual-data-nodes: ds$->{0..1}.ksd_user$->{0..1}
          # 拆分库策略
          database-strategy:
            standard:
              shardingColumn: birthday
              preciseAlgorithmClassName: com.wyb.shardingjdbc.config.BirthdayAlgorithm
          # 分表策略
          table-strategy:
            inline:
              # 分片字段
              sharding-column: age
              # 分片算法表达式
              algorithm-expression: ksd_user$->{age % 2}
    # 配置数据源的读写分离，但是数据库意义的那个要做主从复制
    masterslave:
      # 配置主从名称，可以去任何名字
      name: ms
      # 配置主库master,负责写入
      master-data-source-name: ds1
      # 配置从库slave,负责写入
      slave-data-source-names: ds2,ds3
      # 配置slave节点的负载均衡策略，采用轮询机制
      load-balance-algorithm-type: round_robin
# 整合mybtis的配置
mybatis:
  mapper-locations: classpath:mapper/*.xml
  type-aliases-package: com.wyb.shardingjdbc.entity
debug: false
```

##### 2.1.1.3.新建UserMapper

```java
package com.wyb.shardingjdbc.mapper;

import com.wyb.shardingjdbc.entity.User;
import org.apache.ibatis.annotations.Insert;
import org.apache.ibatis.annotations.Mapper;
import org.apache.ibatis.annotations.Select;
import org.springframework.stereotype.Repository;
import org.springframework.stereotype.Service;

import java.util.List;

@Mapper
public interface UserMapper {
    @Insert("insert into ksd_user(nickname,password,age,sex,birthday) values(#{nickname},#{password},#{age},#{sex},#{birthday})")
    void addUser(User user);

    @Select("select * from ksd_user")
    List<User> findUsers();
}

```

##### 2.1.1.4.新建实体类User

```java
package com.wyb.shardingjdbc.entity;


import lombok.Data;

import java.util.Date;

@Data
public class User {
    // 主键
    private Long id;
    // 用户名
    private String nickname;
    // 密码
    private String password;
    // 年龄
    private Integer age;
    /**
     * 性别 0代表男 1代表女
     */
    private Integer sex;

    private Date birthday;
}

```

##### 2.1.1.5.新建UserController

```java
package com.wyb.shardingjdbc.controller;

import com.wyb.shardingjdbc.entity.User;
import com.wyb.shardingjdbc.mapper.UserMapper;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

import javax.annotation.Resource;
import java.text.ParseException;
import java.text.SimpleDateFormat;
import java.util.Date;
import java.util.List;
import java.util.Random;

@RestController
@RequestMapping("/user")
public class UserController  {
    @Autowired
    private UserMapper userMapper;

    @GetMapping("/save")
    public String insert() throws ParseException {
        User user = new User();
        user.setNickname("user_" + new Random().nextInt());
        user.setPassword("12345" );
        user.setAge(new Random().nextInt(80));
        user.setSex(new Random().nextInt(1));
        SimpleDateFormat simpleDateFormat = new SimpleDateFormat("yyyy-MM-dd");//注意月份是MM
        Date date = simpleDateFormat.parse("1988-12-03");
        user.setBirthday(date);
        userMapper.addUser(user);
        return "success";
    }
    @GetMapping("/listuser")
    public List<User> listuser() {
        return userMapper.findUsers();
    }
}

```

>  注意:
>
> @Autowired那里会报错
>
> ```shell
> Description:
> 
> Field userEntityMapper in com.xxx.xxx.service.UserService required a bean of type 'com.xxx.xxx.dao.UserEntityMapper' that could not be found.
> 
> Action:
> 
> Consider defining a bean of type 'com.xxx.xxx.dao.UserEntityMapper' in your configuration.
> ```
>
> 解决方式：
>
> 1.检查自己写的注解是否错了，并没有。
>
> 2.在网上查找解决方式：如下所示：
>
> 步骤一：
>
> 　　在springboot的配置文件添加，mybatis的配置如下所示：
>
> ```
> mybatis:
>   typeAliasesPackage: com.xxx.xxx.dao.entity
>   mapperLocations: classpath:mapper/*.xml
> ```
>
>  步骤二：
>
> 　　①将接口与对应的实现类放在与application启动类的同一个目录或者他的子目录下，这样注解可以被扫描到，这是最省事的办法。（没测试）
> 　　②或者在启动类上加上@MapperScan或者@ComponentScan注解，手动指定application类要扫描哪些包下的注解，如下所示： 
>
> ```
> @SpringBootApplication
> @ComponentScan(basePackages = {"com.xxx.xxx.dao"})
> ```
>
> 　　③或者在接口上添加@Mapper注解。
>
> ```
> @Mapper
> public interface UserMapper {
> }
> 
> ```
>
> ps：之所以没有找到对应的Bean是因为，@SpringBootApplication没有扫描到。

#### 2.1.2.测试

mysql建库建表

~~~ sql
create database ksd_shading_db;
create table ksd_shading_db.ksd_user(
id int unsigned not null auto_increment,
nickname varchar(50) not null,
password varchar(50) not null,
age int not null,
sex int not null,
birthday timestamp not null,
primary key(id)
)
engine=innodb
default charset=utf8;
~~~



##### 2.1.2.1.插入用户

```
http://localhost:8085/user/save
```

查看console

```shell
2021-05-08 18:22:39.847  INFO 3420 --- [           main] com.alibaba.druid.pool.DruidDataSource   : {dataSource-1} inited
2021-05-08 18:22:40.544  INFO 3420 --- [           main] com.alibaba.druid.pool.DruidDataSource   : {dataSource-2} inited
2021-05-08 18:22:40.582  INFO 3420 --- [           main] com.alibaba.druid.pool.DruidDataSource   : {dataSource-3} inited
2021-05-08 18:22:40.858  INFO 3420 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2021-05-08 18:22:41.044  INFO 3420 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8085 (http) with context path ''
2021-05-08 18:22:41.053  INFO 3420 --- [           main] c.w.s.ShardingJdbcApplication            : Started ShardingJdbcApplication in 3.442 seconds (JVM running for 4.4)
2021-05-08 18:22:51.013  INFO 3420 --- [nio-8085-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
2021-05-08 18:22:51.013  INFO 3420 --- [nio-8085-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
2021-05-08 18:22:51.014  INFO 3420 --- [nio-8085-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 1 ms
2021-05-08 18:22:51.075  INFO 3420 --- [nio-8085-exec-1] ShardingSphere-SQL                       : Rule Type: master-slave
2021-05-08 18:22:51.076  INFO 3420 --- [nio-8085-exec-1] ShardingSphere-SQL                       : SQL: insert into ksd_user(nickname,password,age,sex,birthday) values(?,?,?,?,?) ::: DataSources: ds1
```

插入的数据库为ds1

```shell
SQL: insert into ksd_user(nickname,password,age,sex,birthday) values(?,?,?,?,?) ::: DataSources: ds1
```

##### 2.1.2.2.查看用户

```
http://localhost:8085/user/listuser
```

查看console

```shell
2021-05-08 18:23:48.960  INFO 3420 --- [nio-8085-exec-3] ShardingSphere-SQL                       : Rule Type: master-slave
2021-05-08 18:23:48.960  INFO 3420 --- [nio-8085-exec-3] ShardingSphere-SQL                       : SQL: select * from ksd_user ::: DataSources: ds2
2021-05-08 18:23:57.000  INFO 3420 --- [nio-8085-exec-7] ShardingSphere-SQL                       : Rule Type: master-slave
2021-05-08 18:23:57.000  INFO 3420 --- [nio-8085-exec-7] ShardingSphere-SQL                       : SQL: select * from ksd_user ::: DataSources: ds3
```

看见两次查询的数据库都是不同的，因为采取的是轮询模式

```shell
## 第一次查询
SQL: select * from ksd_user ::: DataSources: ds2
## 第二次查询
SQL: select * from ksd_user ::: DataSources: ds3
```

### 2.2.分库分表

#### 2.2.1相关概念

**为什么要分库分表**

一般机器（4核16G），如果单库MySQL并发（QPS+TPS）超过2k,系统就瘫痪了，最好是将并发量控制在1K左右

分库分表的目的：解决高并发和数据量大的问题

**水平拆分**：同一个表的数据柴刀不同的库不同的表中，可以根据时间、地区、或者某个业务键，也可以通过hash进行拆分，最后体通过路由访问到具体的数据。拆分后的每个表的就够保持一致。

**垂直拆分**：就是把一个有很多字段的表拆分成多个表，或者是多个库上去。每个库表的结构都不一样，每个库表都包含部分字段。一般来说，可以根据业务维度进行拆分，如订单表可拆分成订单、订单支持、订单地址、订单商品、订单扩展等表；也可以根据数据冷热程度拆分，80%冷字段拆到另一个表。

**逻辑表**：水平拆分的数据库或者数据表的相同路基和数据结构表的总称。比如根据用户id%2拆分为2个表，分别是ksd_user0和ksd_user1，他们的逻辑表明是：ksd_user

在sharding_jdbc中定义的方式为：

~~~ yaml
spring:
	shardingsphere:
		tables:
			# ksd_user逻辑表
			ksd_user:
~~~

**分库分表数据节点-**actual-data-nodes

~~~ yaml
tables:
	# ksd_user逻辑表
	ksd_user:
		# 数据节点：多数据源$->{0..N}.逻辑表名$->{0..N}
		actual-data-nodes: ds$->{0..2}.ksd_user$->{0..2}
		# 数据节点：多数据源 不均匀分布
		actual-data-nodes: ds0.ksd_user$->{0..1},ds1.ksd_user$->{2..4}
		# 数据节点：单独指定数据源
		actual-data-nodes: ds0.ksd_user$->{0..2}
		# 数据节点：全部指定数据源
		actual-data-nodes: ds0.ksd_user0,ds0.ksd_user1,ds0.ksd_user2
		
~~~

**分库分表分片算法分片策略**

~~~ yaml
sharding.jdbc.config.sharding:
	# 分片表定义
	tables:
		# 逻辑表
		t_order:
			# 真实表
			actualDataNodes: ds$->{0..1}.t_order${0..1}
			# 数据源分片策略
			databaseStrategy:
			inline:
				# 分片键
				shardingColumn: user_id
				# 分片算法
				algorithmInlineExpression: t_order$->{user_id%2}
			# 表分片策略
			tableStrategy:
			inline:
				# 分片键
				shardingColumn: order_id
				# 分片算法
				algorithmInlineExpression: t_order$->{order_id%2}
~~~

**数据分片：**

- 数据源分片 -- 将数据放到哪个库里面去 
- 表分片 -- 将数据放到哪个表里面去

这两个是不同维度的分片规则，都有两部分构成

- 分片键

  用于分片的数据库字段，是将数据库(表)水平拆分的关键字段。例：将订单表中的订单主键的尾数取模分片，则订单主键为分片字段。 SQL中如果无分片字段，将执行全路由，性能较差。 除了对单分片字段的支持，ShardingSphere也支持根据多个字段进行分片。

- 分片算法

  通过分片算法将数据分片，支持通过`=`、`>=`、`<=`、`>`、`<`、`BETWEEN`和`IN`分片。分片算法需要应用方开发者自行实现，可实现的灵活度非常高。

  目前提供4种分片算法。由于分片算法和业务实现紧密相关，因此并未提供内置分片算法，而是通过分片策略将各种场景提炼出来，提供更高层级的抽象，并提供接口让应用开发者自行实现分片算法。

  - 精确分片算法

  对应PreciseShardingAlgorithm，用于处理使用单一键作为分片键的=与IN进行分片的场景。需要配合StandardShardingStrategy使用。

  - 范围分片算法

  对应RangeShardingAlgorithm，用于处理使用单一键作为分片键的BETWEEN AND、>、<、>=、<=进行分片的场景。需要配合StandardShardingStrategy使用。

  - 复合分片算法

  对应ComplexKeysShardingAlgorithm，用于处理使用多键作为分片键进行分片的场景，包含多个分片键的逻辑较复杂，需要应用开发者自行处理其中的复杂度。需要配合ComplexShardingStrategy使用。

  - Hint分片算法

  对应HintShardingAlgorithm，用于处理使用Hint行分片的场景。需要配合HintShardingStrategy使用。

**分片策略**

包含分片键和分片算法，由于分片算法的独立性，将其独立抽离。真正可用于分片操作的是分片键 + 分片算法，也就是分片策略。目前提供5种分片策略

>  第一种：none

对应NoneShardingStratery，不分片策略，sql会发给所有节点但去执行，这个规则没有子项目可以配置。

> 第二种：inline 行表达式分片策略(核心)

对应InlineShardingStrategy。使用Groovy的表达式，提供对SQL语句中的=和IN的分片操作支持，只支持单分片键。对于简单的分片算法，可以通过简单的配置使用，从而避免繁琐的Java代码开发，如: `t_user_$->{u_id % 8}` 表示t_user表根据u_id模8，而分成8张表，表名称为`t_user_0`到`t_user_7`。

> 第三种：Hint分片策略

对应HintShardingStrategy。通过Hint指定分片值而非从SQL中提取分片值的方式进行分片的策略。

> 第四种：复合分片策略

对应ComplexShardingStrategy。复合分片策略。提供对SQL语句中的=, >, <, >=, <=, IN和BETWEEN AND的分片操作支持。ComplexShardingStrategy支持多分片键，由于多分片键之间的关系复杂，因此并未进行过多的封装，而是直接将分片键值组合以及分片操作符透传至分片算法，完全由应用开发者实现，提供最大的灵活度。

> 第五种：标准分片策略 -- 根据时间日期

- 对应StandardShardingStrategy。提供对SQL语句中的=, >, <, >=, <=, IN和BETWEEN AND的分片操作支持。
- StandardShardingStrategy只支持单分片键，提供PreciseShardingAlgorithm和RangeShardingAlgorithm两个分片算法。
- PreciseShardingAlgorithm是必选的，用于处理=和IN的分片。
- RangeShardingAlgorithm是可选的，用于处理BETWEEN AND, >, <, >=, <=分片，如果不配置RangeShardingAlgorithm，SQL中的BETWEEN AND将按照全库路由处理。



#### 2.2.2操作

##### 2.2.2.1.测试按字段分库分表（inline策略）

数据库准备，在mysql-master中执行

~~~ sql
create table ksd_order_db.ksd_user0(
id int unsigned not null auto_increment,
nickname varchar(50) not null,
password varchar(50) not null,
age int not null,
sex int not null,
birthday timestamp not null,
primary key(id)
)
engine=innodb
default charset=utf8;

create table ksd_order_db.ksd_user1(
id int unsigned not null auto_increment,
nickname varchar(50) not null,
password varchar(50) not null,
age int not null,
sex int not null,
birthday timestamp not null,
primary key(id)
)
engine=innodb
default charset=utf8;
~~~

首先更新application.yaml文件，改成可配置方式

~~~ yaml
server:
  port: 8085
spring:
  main:
    allow-bean-definition-overriding: true
  profiles:
#    active: ms
    active: sub
# 整合mybtis的配置
mybatis:
  mapper-locations: classpath:mapper/*.xml
  type-aliases-package: com.wyb.shardingjdbc.entity
debug: false

~~~

application-sub.yaml

~~~ yaml
spring:
  shardingsphere:
    # 参数配置，显示sql
    props:
      sql:
        show: true
    # 配置数据源
    datasource:
      # 给每个数据源取别名
      names: ds0,ds1
      # 给master ds1配置数据库连接信息
      ds0:
        # 配置druid数据库源
        type: com.alibaba.druid.pool.DruidDataSource
        driver-class-name: com.mysql.cj.jdbc.Driver
        url: jdbc:mysql://localhost:13311/ksd_order_db?useUnicode=true&characterEncoding=utf8
        username: root
        password: 123456
        maxPoolSize: 100
        minPoolSize: 5
      # 配置slave
      ds1:
        # 配置druid数据库源
        type: com.alibaba.druid.pool.DruidDataSource
        driver-class-name: com.mysql.cj.jdbc.Driver
        url: jdbc:mysql://localhost:13312/ksd_order_db?useUnicode=true&characterEncoding=utf8
        username: root
        password: 123456
        maxPoolSize: 100
        minPoolSize: 5
    # 配置sharding
    sharding:
      # 默认数据源，主要用于写，注意一定要配置读写分离
      # 如果不配置，那就会把所有节点都当作slave节点
      default-data-source-name: ds0
      # 配置分表的规则
      tables:
        # ksd_user 逻辑表名
        ksd_user:
          # 数据节点：数据源$->{0..N}.逻辑表名$->{0..N}
          actual-data-nodes: ds$->{0..1}.ksd_user$->{0..1}
          # 拆分库策略
          database-strategy:
#            standard:
#              shardingColumn: birthday
#              preciseAlgorithmClassName: com.wyb.shardingjdbc.config.BirthdayAlgorithm
            inline:
              # 分片字段
              sharding-column: age
              # 分片算法表达式
              algorithm-expression: ds$->{age % 2}
          # 分表策略
          table-strategy:
            inline:
              # 分片字段
              sharding-column: age
              # 分片算法表达式
              algorithm-expression: ksd_user$->{age % 2}
~~~

> 注意：
>
> 此处配置的是，库和表都是按照age%2之后的结果来分配的
>
> 比如：age=1，应该分配到ds1.ksd_user1中



测试插入一行age为1的数据

~~~ java
package com.wyb.shardingjdbc;

import com.wyb.shardingjdbc.entity.User;
import com.wyb.shardingjdbc.mapper.UserMapper;
import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.autoconfigure.EnableAutoConfiguration;
import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration;
import org.springframework.boot.test.context.SpringBootTest;

import java.text.ParseException;
import java.text.SimpleDateFormat;
import java.util.Date;
import java.util.Random;

@SpringBootTest
class ShardingJdbcApplicationTests {

	@Autowired
	private UserMapper userMapper;
	@Test
	void contextLoads() throws ParseException {
		User user = new User();
		user.setNickname("user_" + new Random().nextInt());
		user.setPassword("12345" );
		// user.setAge(new Random().nextInt(80));
		user.setAge(1);
		user.setSex(new Random().nextInt(1));
		SimpleDateFormat simpleDateFormat = new SimpleDateFormat("yyyy-MM-dd");//注意月份是MM
		Date date = simpleDateFormat.parse("1988-12-03");
		user.setBirthday(date);
		userMapper.addUser(user);
	}

}

~~~



执行日志

~~~ shell

 ShardingSphere-SQL                       : Actual SQL: ds1 ::: insert into ksd_user1 (nickname, password, age, sex, birthday) VALUES (?, ?, ?, ?, ?) ::: [user_477386648, 12345, 1, 0, 1988-12-03 00:00:00.0]
~~~

日志中显示插入到ds1中的ksd_user1

查看数据库表中数据

~~~ shell
C:\Windows\System32>docker exec -it mysql-slave /bin/bash
root@fcd84e64cc03:/# mysql -uroot -p123456

mysql> use ksd_order_db;
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A

Database changed
mysql> select * from ksd_user0;
Empty set (0.00 sec)

mysql> select * from ksd_user1;
+----+----------------+----------+-----+-----+---------------------+
| id | nickname       | password | age | sex | birthday            |
+----+----------------+----------+-----+-----+---------------------+
|  1 | user_477386648 | 12345    |   1 |   0 | 1988-12-03 00:00:00 |
+----+----------------+----------+-----+-----+---------------------+
1 row in set (0.00 sec)

~~~



##### 2.2.2.2 测试标准策略

测试根据生日分库（是否在2020年之前在ds0,2021年之前在ds1），根据年龄%2分表

更改application.yaml

~~~ yaml   
server:
  port: 8085
spring:
  main:
    allow-bean-definition-overriding: true
  profiles:
#    active: ms
#    active: sub
    active: stand
# 整合mybtis的配置
mybatis:
  mapper-locations: classpath:mapper/*.xml
  type-aliases-package: com.wyb.shardingjdbc.entity
debug: false
~~~

生成新的application-stand.yaml

~~~ yaml
## 配置根据age是否为基偶数分库分表
spring:
  shardingsphere:
    # 参数配置，显示sql
    props:
      sql:
        show: true
    # 配置数据源
    datasource:
      # 给每个数据源取别名
      names: ds0,ds1
      # 给master ds1配置数据库连接信息
      ds0:
        # 配置druid数据库源
        type: com.alibaba.druid.pool.DruidDataSource
        driver-class-name: com.mysql.cj.jdbc.Driver
        url: jdbc:mysql://localhost:13311/ksd_order_db?useUnicode=true&characterEncoding=utf8
        username: root
        password: 123456
        maxPoolSize: 100
        minPoolSize: 5
      # 配置slave
      ds1:
        # 配置druid数据库源
        type: com.alibaba.druid.pool.DruidDataSource
        driver-class-name: com.mysql.cj.jdbc.Driver
        url: jdbc:mysql://localhost:13312/ksd_order_db?useUnicode=true&characterEncoding=utf8
        username: root
        password: 123456
        maxPoolSize: 100
        minPoolSize: 5
    # 配置sharding
    sharding:
      # 默认数据源，主要用于写，注意一定要配置读写分离
      # 如果不配置，那就会把所有节点都当作slave节点
      default-data-source-name: ds0
      # 配置分表的规则
      tables:
        # ksd_user 逻辑表名
        ksd_user:
          # 数据节点：数据源$->{0..N}.逻辑表名$->{0..N}
          actual-data-nodes: ds$->{0..1}.ksd_user$->{0..1}
          # 拆分库策略
          database-strategy:
            standard:
              # 把生日2020年放一个库，2021年放一个库
              shardingColumn: birthday
              preciseAlgorithmClassName: com.wyb.shardingjdbc.config.BirthdayAlgorithm
          # 分表策略
          table-strategy:
            inline:
              # 分片字段
              sharding-column: age
              # 分片算法表达式
              algorithm-expression: ksd_user$->{age % 2}

~~~

BirthdayAlgorithm标准策略

是否在2020年之前在ds0,2021年之前在ds1

~~~ java
package com.wyb.shardingjdbc.config;

import org.apache.shardingsphere.api.sharding.standard.PreciseShardingAlgorithm;
import org.apache.shardingsphere.api.sharding.standard.PreciseShardingValue;

import java.util.*;

public class BirthdayAlgorithm implements PreciseShardingAlgorithm<Date>{
    List<Date> dateList = new ArrayList<>();

    {
        Calendar calendar1 = Calendar.getInstance();
        calendar1.set(2020,1,1,0,0,0);
        Calendar calendar2 = Calendar.getInstance();
        calendar2.set(2021,1,1,0,0,0);
        // Calendar calendar3 = Calendar.getInstance();
        // calendar3.set(2022,1,1,0,0,0);
        dateList.add(calendar1.getTime());
        dateList.add(calendar2.getTime());
        // dateList.add(calendar3.getTime());
    }

    @Override
    public String doSharding(Collection<String> collection, PreciseShardingValue<Date> preciseShardingValue) {
        // 获取属性数据库的值
        Date date = preciseShardingValue.getValue();
        // 获取数据源的名称信息列表
        Iterator<String> iterator = collection.iterator();
        String target = null;
        for (Date s : dateList) {
            target = iterator.next();
            // 如果数据万余指定日期直接返回
            if (date.before(s)) {
                break;
            }
        }
        return target; // 最后返回的是ds0,ds1
    }
}

~~~

测试1999 和2020 年的人

~~~ java
package com.wyb.shardingjdbc;

import com.wyb.shardingjdbc.entity.User;
import com.wyb.shardingjdbc.mapper.UserMapper;
import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.autoconfigure.EnableAutoConfiguration;
import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration;
import org.springframework.boot.test.context.SpringBootTest;

import java.text.ParseException;
import java.text.SimpleDateFormat;
import java.util.Date;
import java.util.Random;

@SpringBootTest
class ShardingJdbcApplicationTests {

	@Autowired
	private UserMapper userMapper;
	@Test
	void contextLoads() throws ParseException {
		User user = new User();
		user.setNickname("user_" + new Random().nextInt(100));
		user.setPassword("12345" );
		user.setAge(new Random().nextInt(80));
		user.setSex(new Random().nextInt(1));
		SimpleDateFormat simpleDateFormat = new SimpleDateFormat("yyyy-MM-dd");//注意月份是MM
		Date date = simpleDateFormat.parse("1999-05-09");
        ## Date date = simpleDateFormat.parse("2020-05-09");
		user.setBirthday(date);
		userMapper.addUser(user);
	}

}

~~~

1999 年的人age随机的人插入的日志

~~~ shell
2021-05-09 00:56:45.932  INFO 6660 --- [           main] ShardingSphere-SQL                       : Actual SQL: ds0 ::: insert into ksd_user1 (nickname, password, age, sex, birthday) VALUES (?, ?, ?, ?, ?) ::: [user_81, 12345, 41, 0, 1999-05-09 00:00:00.0]

2021-05-09 00:59:15.658  INFO 9200 --- [           main] ShardingSphere-SQL                       : Actual SQL: ds0 ::: insert into ksd_user0 (nickname, password, age, sex, birthday) VALUES (?, ?, ?, ?, ?) ::: [user_35, 12345, 22, 0, 1999-05-09 00:00:00.0]


~~~

2020  年的人age随机的人插入的日志

~~~ shell
2021-05-09 01:00:26.593  INFO 8856 --- [           main] ShardingSphere-SQL                       : Actual SQL: ds1 ::: insert into ksd_user1 (nickname, password, age, sex, birthday) VALUES (?, ?, ?, ?, ?) ::: [user_43, 12345, 15, 0, 2020-05-09 00:00:00.0]

2021-05-09 01:01:01.184  INFO 8608 --- [           main] ShardingSphere-SQL                       : Actual SQL: ds1 ::: insert into ksd_user0 (nickname, password, age, sex, birthday) VALUES (?, ?, ?, ?, ?) ::: [user_54, 12345, 24, 0, 2020-05-09 00:00:00.0]

~~~

此时查询所有的结果

~~~ shell
[{"id":1,"nickname":"user_35","password":"12345","age":22,"sex":0,"birthday":"1999-05-08T16:00:00.000+00:00"},{"id":1,"nickname":"user_81","password":"12345","age":41,"sex":0,"birthday":"1999-05-08T16:00:00.000+00:00"},{"id":2,"nickname":"user_0","password":"12345","age":19,"sex":0,"birthday":"1999-05-08T16:00:00.000+00:00"},{"id":1,"nickname":"user_35","password":"12345","age":22,"sex":0,"birthday":"1999-05-08T16:00:00.000+00:00"},{"id":2,"nickname":"user_54","password":"12345","age":24,"sex":0,"birthday":"2020-05-08T16:00:00.000+00:00"},{"id":1,"nickname":"user_81","password":"12345","age":41,"sex":0,"birthday":"1999-05-08T16:00:00.000+00:00"},{"id":2,"nickname":"user_0","password":"12345","age":19,"sex":0,"birthday":"1999-05-08T16:00:00.000+00:00"},{"id":3,"nickname":"user_43","password":"12345","age":15,"sex":0,"birthday":"2020-05-08T16:00:00.000+00:00"}]
~~~

id会有重复问题

##### 2.2.2.3.分布式主键配置

数据分片后，不同数据节点生成全局唯一主键是非常棘手的问题。同一个逻辑表内的不同实际表之间的自增键由于无法互相感知而产生重复主键。 虽然可通过约束自增主键初始值和步长的方式避免碰撞，但需引入额外的运维规则，使解决方案缺乏完整性和可扩展性。

目前有许多第三方解决方案可以完美解决这个问题，如UUID等依靠特定算法自生成不重复键，或者通过引入主键生成服务等。为了方便用户使用、满足不同用户不同使用场景的需求， ShardingSphere不仅提供了内置的分布式主键生成器，例如UUID、SNOWFLAKE，还抽离出分布式主键生成器的接口，方便用户自行实现自定义的自增主键生成器。

###### UUID

采用UUID.randomUUID()的方式产生分布式主键。

###### SNOWFLAKE

ShardingSphere提供灵活的配置分布式主键生成策略方式。 在分片规则配置模块可配置每个表的主键生成策略，默认使用雪花算法（snowflake）生成64bit的长整型数据。

雪花算法是由Twitter公布的分布式主键生成算法，它能够保证不同进程主键的不重复性，以及相同进程主键的有序性。

在同一个进程中，它首先是通过时间位保证不重复，如果时间相同则是通过序列位保证。 同时由于时间位是单调递增的，且各个服务器如果大体做了时间同步，那么生成的主键在分布式环境可以认为是总体有序的，这就保证了对索引字段的插入的高效性。例如MySQL的Innodb存储引擎的主键。

使用雪花算法生成的主键，二进制表示形式包含4部分，从高位到低位分表为：1bit符号位、41bit时间戳位、10bit工作进程位以及12bit序列号位。

- 符号位(1bit)

预留的符号位，恒为零。

- 时间戳位(41bit)

41位的时间戳可以容纳的毫秒数是2的41次幂，一年所使用的毫秒数是：`365 * 24 * 60 * 60 * 1000`。通过计算可知：

```java
Math.pow(2, 41) / (365 * 24 * 60 * 60 * 1000L);
```

结果约等于69.73年。ShardingSphere的雪花算法的时间纪元从2016年11月1日零点开始，可以使用到2086年，相信能满足绝大部分系统的要求。

- 工作进程位(10bit)

该标志在Java进程内是唯一的，如果是分布式应用部署应保证每个工作进程的id是不同的。该值默认为0，可通过属性设置。

- 序列号位(12bit)

该序列是用来在同一个毫秒内生成不同的ID。如果在这个毫秒内生成的数量超过4096(2的12次幂)，那么生成器会等待到下个毫秒继续生成。

**时钟回拨**

服务器时钟回拨会导致产生重复序列，因此默认分布式主键生成器提供了一个最大容忍的时钟回拨毫秒数。 如果时钟回拨的时间超过最大容忍的毫秒数阈值，则程序报错；如果在可容忍的范围内，默认分布式主键生成器会等待时钟同步到最后一次主键生成的时间后再继续工作。 最大容忍的时钟回拨毫秒数的默认值为0，可通过属性设置。

###### LEAF

在5.0.0版本之前，借鉴[Leaf](https://tech.meituan.com/2017/04/21/mt-leaf.html)，主要分为Leaf-segment和Leaf-snowflake两种方案。ShardingSphere在4.0.0-RC2-release版本中实现了Leaf-segment，在4.0.0-RC3-release版本中实现了Leaf-snowflake。

从5.0.0版本起，以上两个实现从ShardingSphere中移除。我们重新适配了第三方的[Leaf开源实现](https://github.com/Meituan-Dianping/Leaf)，并移动到[OpenSharding](https://github.com/opensharding/sharding-keygen-leaf)仓库中。具体使用方式，请参考[OpenSharding/sharding-keygen-leaf](https://github.com/opensharding/sharding-keygen-leaf)项目。



> 注意：
>
> 主键列不能自增长，数据类型是：bigint(20)

```yaml
spring:
  shardingsphere:
      sharding:
      	tables:
      		# ksd_user 逻辑表名
      		ksd_user:
      			key-generator:
      				column: id
      				type: SNOWFLAKE
```

更改表结构

~~~ sql
drop table ksd_order_db.ksd_user0;
create table ksd_order_db.ksd_user0(
id bigint not null,
nickname varchar(50) not null,
password varchar(50) not null,
age int not null,
sex int not null,
birthday timestamp not null,
primary key(id)
)
engine=innodb
default charset=utf8;

drop table ksd_order_db.ksd_user1;
create table ksd_order_db.ksd_user1(
id bigint not null,
nickname varchar(50) not null,
password varchar(50) not null,
age int not null,
sex int not null,
birthday timestamp not null,
primary key(id)
)
engine=innodb
default charset=utf8;
~~~

yaml配置

~~~ yaml
## 配置根据age是否为基偶数分库分表
spring:
  shardingsphere:
    # 参数配置，显示sql
    props:
      sql:
        show: true
    # 配置数据源
    datasource:
      # 给每个数据源取别名
      names: ds0,ds1
      # 给master ds1配置数据库连接信息
      ds0:
        # 配置druid数据库源
        type: com.alibaba.druid.pool.DruidDataSource
        driver-class-name: com.mysql.cj.jdbc.Driver
        url: jdbc:mysql://localhost:13311/ksd_order_db?useUnicode=true&characterEncoding=utf8
        username: root
        password: 123456
        maxPoolSize: 100
        minPoolSize: 5
      # 配置slave
      ds1:
        # 配置druid数据库源
        type: com.alibaba.druid.pool.DruidDataSource
        driver-class-name: com.mysql.cj.jdbc.Driver
        url: jdbc:mysql://localhost:13312/ksd_order_db?useUnicode=true&characterEncoding=utf8
        username: root
        password: 123456
        maxPoolSize: 100
        minPoolSize: 5
    # 配置sharding
    sharding:
      # 默认数据源，主要用于写，注意一定要配置读写分离
      # 如果不配置，那就会把所有节点都当作slave节点
      default-data-source-name: ds0
      # 配置分表的规则
      tables:
        # ksd_user 逻辑表名
        ksd_user:
          # 分布式主键
          key-generator:
              column: id
              type: SNOWFLAKE
          # 数据节点：数据源$->{0..N}.逻辑表名$->{0..N}
          actual-data-nodes: ds$->{0..1}.ksd_user$->{0..1}
          # 拆分库策略
          database-strategy:
            standard:
              # 把生日2020年放一个库，2021年放一个库
              shardingColumn: birthday
              preciseAlgorithmClassName: com.wyb.shardingjdbc.config.BirthdayAlgorithm
          # 分表策略
          table-strategy:
            inline:
              # 分片字段
              sharding-column: age
              # 分片算法表达式
              algorithm-expression: ksd_user$->{age % 2}
~~~



运行结果

~~~ shell
2021-05-09 21:08:50.653  INFO 14876 --- [           main] ShardingSphere-SQL                       : Actual SQL: ds1 ::: insert into ksd_user1 (nickname, password, age, sex, birthday, id) VALUES (?, ?, ?, ?, ?, ?) ::: [user_54, 12345, 37, 0, 2020-05-09 00:00:00.0, 598259292230909953]
598259292230909953
~~~

多插入几条查看

~~~
[{"id":598259642618871809,"nickname":"user_28","password":"12345","age":27,"sex":0,"birthday":"1999-05-08T16:00:00.000+00:00"},{"id":598259730908971009,"nickname":"user_93","password":"12345","age":5,"sex":0,"birthday":"1999-05-08T16:00:00.000+00:00"},{"id":598259292230909953,"nickname":"user_54","password":"12345","age":37,"sex":0,"birthday":"2020-05-08T16:00:00.000+00:00"},{"id":598259642618871809,"nickname":"user_28","password":"12345","age":27,"sex":0,"birthday":"1999-05-08T16:00:00.000+00:00"},{"id":598259730908971009,"nickname":"user_93","password":"12345","age":5,"sex":0,"birthday":"1999-05-08T16:00:00.000+00:00"},{"id":598259855421079553,"nickname":"user_41","password":"12345","age":11,"sex":0,"birthday":"2020-05-08T16:00:00.000+00:00"}]
~~~

##### 2.2.2.4.测试按年月分表

建表

~~~ sql
drop table ksd_order_db.ksd_user_order_202101;
create table ksd_order_db.ksd_user_order_202101(
order_id bigint not null,
user_id bigint not null,
orde_rnumber varchar(50) not null,
create_time datetime not null,
yearmonth  varchar(20) not null,
primary key(order_id)
)
engine=innodb
default charset=utf8;

drop table ksd_order_db.ksd_user_order_202102;
create table ksd_order_db.ksd_user_order_202102(
order_id bigint not null,
user_id bigint not null,
orde_rnumber varchar(50) not null,
create_time datetime not null,
yearmonth  varchar(20) not null,
primary key(order_id)
)
engine=innodb
default charset=utf8;

drop table ksd_order_db.ksd_user_order_202103;
create table ksd_order_db.ksd_user_order_202103(
order_id bigint not null,
user_id bigint not null,
orde_rnumber varchar(50) not null,
create_time datetime not null,
yearmonth  varchar(20) not null,
primary key(order_id)
)
engine=innodb
default charset=utf8;

drop table ksd_order_db.ksd_user_order_202201;
create table ksd_order_db.ksd_user_order_202201(
order_id bigint not null,
user_id bigint not null,
orde_rnumber varchar(50) not null,
create_time datetime not null,
yearmonth  varchar(20) not null,
primary key(order_id)
)
engine=innodb
default charset=utf8;

drop table ksd_order_db.ksd_user_order_202202;
create table ksd_order_db.ksd_user_order_202202(
order_id bigint not null,
user_id bigint not null,
orde_rnumber varchar(50) not null,
create_time datetime not null,
yearmonth  varchar(20) not null,
primary key(order_id)
)
engine=innodb
default charset=utf8;

drop table ksd_order_db.ksd_user_order_202203;
create table ksd_order_db.ksd_user_order_202203(
order_id bigint not null,
user_id bigint not null,
orde_rnumber varchar(50) not null,
create_time datetime not null,
yearmonth  varchar(20) not null,
primary key(order_id)
)
engine=innodb
default charset=utf8;
~~~

配置application-yearmonth.yaml

~~~ yaml
## 配置根据yearmonth是拆分表
spring:
  shardingsphere:
    # 参数配置，显示sql
    props:
      sql:
        show: true
    # 配置数据源
    datasource:
      # 给每个数据源取别名
      names: ds0,ds1
      # 给master ds1配置数据库连接信息
      ds0:
        # 配置druid数据库源
        type: com.alibaba.druid.pool.DruidDataSource
        driver-class-name: com.mysql.cj.jdbc.Driver
        url: jdbc:mysql://localhost:13311/ksd_order_db?useUnicode=true&characterEncoding=utf8
        username: root
        password: 123456
        maxPoolSize: 100
        minPoolSize: 5
      # 配置slave
      ds1:
        # 配置druid数据库源
        type: com.alibaba.druid.pool.DruidDataSource
        driver-class-name: com.mysql.cj.jdbc.Driver
        url: jdbc:mysql://localhost:13312/ksd_order_db?useUnicode=true&characterEncoding=utf8
        username: root
        password: 123456
        maxPoolSize: 100
        minPoolSize: 5
    # 配置sharding
    sharding:
      # 默认数据源，主要用于写，注意一定要配置读写分离
      # 如果不配置，那就会把所有节点都当作slave节点
      default-data-source-name: ds0
      # 配置分表的规则
      tables:
        # ksd_user 逻辑表名
        ksd_user_order:
          # 数据节点：${1..3}.collect{t -> t.toString().padLeft(2,'0')}的意思是给月份用0左补全两位
          actual-data-nodes: ds0.ksd_user_order_$->{2021..2022}${(1..3).collect{t->t.toString().padLeft(2,'0')}}
          # 分布式主键
          key-generator:
              column: order_id
              type: SNOWFLAKE
          # 分表策略
          table-strategy:
            inline:
              # 分片字段
              sharding-column: yearmonth
              # 分片算法表达式
              algorithm-expression: ksd_user_order_$->{yearmonth}
#              algorithm-expression: com.wyb.shardingjdbc.config.YearMonthShardingAlgorithm
~~~

实体类UserOrder

~~~ java
package com.wyb.shardingjdbc.entity;

import java.util.Date;

public class UserOrder {
    private long order_id;
    private long user_id ;
    private String orde_rnumber;
    private Date create_time;
    private String yearmonth  ;

    public UserOrder() {
    }

    public UserOrder(long order_id, long user_id, String orde_rnumber, Date create_time, String yearmonth) {
        this.order_id = order_id;
        this.user_id = user_id;
        this.orde_rnumber = orde_rnumber;
        this.create_time = create_time;
        this.yearmonth = yearmonth;
    }

    public long getOrder_id() {
        return order_id;
    }

    public void setOrder_id(long order_id) {
        this.order_id = order_id;
    }

    public long getUser_id() {
        return user_id;
    }

    public void setUser_id(long user_id) {
        this.user_id = user_id;
    }

    public String getOrde_rnumber() {
        return orde_rnumber;
    }

    public void setOrde_rnumber(String orde_rnumber) {
        this.orde_rnumber = orde_rnumber;
    }

    public Date getCreate_time() {
        return create_time;
    }

    public void setCreate_time(Date create_time) {
        this.create_time = create_time;
    }

    public String getYearmonth() {
        return yearmonth;
    }

    public void setYearmonth(String yearmonth) {
        this.yearmonth = yearmonth;
    }

    @Override
    public String toString() {
        return "UserOrder{" +
                "order_id=" + order_id +
                ", user_id=" + user_id +
                ", orde_rnumber='" + orde_rnumber + '\'' +
                ", create_time=" + create_time +
                ", yearmonth='" + yearmonth + '\'' +
                '}';
    }
}
~~~

UserOrderController

~~~ java
package com.wyb.shardingjdbc.controller;

import com.wyb.shardingjdbc.entity.UserOrder;
import com.wyb.shardingjdbc.mapper.UserOrderMapper;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

import java.text.ParseException;
import java.text.SimpleDateFormat;
import java.util.Date;
import java.util.List;
import java.util.Random;

@RestController
@RequestMapping("/order")
public class UserOrderController {

    @Autowired
    private UserOrderMapper userOrderMapper;

    @GetMapping("/addorder")
    public String addOrder() throws ParseException {
        UserOrder order = new UserOrder();
        order.setUser_id(new Random().nextInt(100));
        order.setOrde_rnumber("12345" );
        SimpleDateFormat simpleDateFormat = new SimpleDateFormat("yyyy-MM-dd");//注意月份是MM
        // Date date = simpleDateFormat.parse("1999-05-09");
        Date date = simpleDateFormat.parse("2020-05-09");
        order.setCreate_time(date);
        String[] yms = {"202101","202102","202103","202201","202202","202203"};
        order.setYearmonth(yms[new Random().nextInt(6)]);
        userOrderMapper.addOrder(order);
        return "success";
    }

    @GetMapping("/listorders")
    public List<UserOrder> listOrders() {
        return userOrderMapper.listOrders();
    }
}
~~~

UserOrderMapper

~~~ java
package com.wyb.shardingjdbc.mapper;

import com.wyb.shardingjdbc.entity.UserOrder;
import org.apache.ibatis.annotations.Insert;
import org.apache.ibatis.annotations.Mapper;
import org.apache.ibatis.annotations.Options;
import org.apache.ibatis.annotations.Select;

import java.util.List;

@Mapper
public interface UserOrderMapper {
    @Insert("insert into ksd_user_order(user_id,orde_rnumber,create_time,yearmonth) " +
            "values(#{user_id},#{orde_rnumber},#{create_time},#{yearmonth})")
    @Options(useGeneratedKeys = true,keyColumn = "order_id",keyProperty = "order_id")
    void addOrder(UserOrder userOrder);

    @Select("select * from ksd_user_order")
    List<UserOrder> listOrders();
}

~~~

测试插入202101数据

~~~ java
    @Autowired
    private UserOrderMapper userOrderMapper;
    @Test
    void contextLoads1() throws ParseException {
        UserOrder order = new UserOrder();
        order.setUser_id(new Random().nextInt(100));
        order.setOrde_rnumber("12345" );
        SimpleDateFormat simpleDateFormat = new SimpleDateFormat("yyyy-MM-dd");//注意月份是MM
        Date date = simpleDateFormat.parse("2020-05-09");
        order.setCreate_time(date);
        String[] yms = {"202101","202102","202103","202201","202202","202203"};
        // order.setYearmonth(yms[new Random().nextInt(6)]);
        order.setYearmonth(yms[0]);
        userOrderMapper.addOrder(order);
    }
~~~

日志

~~~ shell
Actual SQL: ds0 ::: insert into ksd_user_order_202101 (user_id, orde_rnumber, create_time, yearmonth, order_id) VALUES (?, ?, ?, ?, ?) ::: [14, 12345, 2020-05-09 00:00:00.0, 202101, 598278039259840513]
~~~



看看是否在表ksd_user_order_202101中

~~~ shell
mysql> select * from ksd_user_order_202101;
+--------------------+---------+--------------+---------------------+-----------+
| order_id           | user_id | orde_rnumber | create_time         | yearmonth |
+--------------------+---------+--------------+---------------------+-----------+
| 598278039259840513 |      14 | 12345        | 2020-05-09 00:00:00 | 202101    |
+--------------------+---------+--------------+---------------------+-----------+
1 row in set (0.00 sec)
~~~

##### 2.2.2.5.分布式事务

数据库事务需要满足`ACID`（原子性、一致性、隔离性、持久性）四个特性。

- 原子性（Atomicity）指事务作为整体来执行，要么全部执行，要么全不执行。
- 一致性（Consistency）指事务应确保数据从一个一致的状态转变为另一个一致的状态。
- 隔离性（Isolation）指多个事务并发执行时，一个事务的执行不应影响其他事务的执行。
- 持久性（Durability）指已提交的事务修改数据会被持久保存。

在单一数据节点中，事务仅限于对单一数据库资源的访问控制，称之为本地事务。几乎所有的成熟的关系型数据库都提供了对本地事务的原生支持。 但是在基于微服务的分布式应用环境下，越来越多的应用场景要求对多个服务的访问及其相对应的多个数据库资源能纳入到同一个事务当中，分布式事务应运而生。

关系型数据库虽然对本地事务提供了完美的`ACID`原生支持。 但在分布式的场景下，它却成为系统性能的桎梏。如何让数据库在分布式场景下满足`ACID`的特性或找寻相应的替代方案，是分布式事务的重点工作。

###### 本地事务

在不开启任何分布式事务管理器的前提下，让每个数据节点各自管理自己的事务。 它们之间没有协调以及通信的能力，也并不互相知晓其他数据节点事务的成功与否。 本地事务在性能方面无任何损耗，但在强一致性以及最终一致性方面则力不从心。

###### 两阶段提交

XA协议最早的分布式事务模型是由`X/Open`国际联盟提出的`X/Open Distributed Transaction Processing（DTP）`模型，简称XA协议。

基于XA协议实现的分布式事务对业务侵入很小。 它最大的优势就是对使用方透明，用户可以像使用本地事务一样使用基于XA协议的分布式事务。 XA协议能够严格保障事务`ACID`特性。

严格保障事务`ACID`特性是一把双刃剑。 事务执行在过程中需要将所需资源全部锁定，它更加适用于执行时间确定的短事务。 对于长事务来说，整个事务进行期间对数据的独占，将导致对热点数据依赖的业务系统并发性能衰退明显。 因此，在高并发的性能至上场景中，基于XA协议的分布式事务并不是最佳选择。

###### 柔性事务

如果将实现了`ACID`的事务要素的事务称为刚性事务的话，那么基于`BASE`事务要素的事务则称为柔性事务。 `BASE`是基本可用、柔性状态和最终一致性这三个要素的缩写。

- 基本可用（Basically Available）保证分布式事务参与方不一定同时在线。
- 柔性状态（Soft state）则允许系统状态更新有一定的延时，这个延时对客户来说不一定能够察觉。
- 而最终一致性（Eventually consistent）通常是通过消息传递的方式保证系统的最终一致性。

在`ACID`事务中对隔离性的要求很高，在事务执行过程中，必须将所有的资源锁定。 柔性事务的理念则是通过业务逻辑将互斥锁操作从资源层面上移至业务层面。通过放宽对强一致性要求，来换取系统吞吐量的提升。

基于`ACID`的强一致性事务和基于`BASE`的最终一致性事务都不是银弹，只有在最适合的场景中才能发挥它们的最大长处。 可通过下表详细对比它们之间的区别，以帮助开发者进行技术选型。

添加依赖

~~~ xml
		<!-- 分布式事务-->
		<dependency>
			<groupId>io.shardingsphere</groupId>
			<artifactId>sharding-transaction-spring-boot-starter</artifactId>
			<version>3.1.0</version>
		</dependency>
~~~

UserOderService

~~~ java
package com.wyb.shardingjdbc.service;

import com.wyb.shardingjdbc.entity.User;
import com.wyb.shardingjdbc.entity.UserOrder;
import com.wyb.shardingjdbc.mapper.UserMapper;
import com.wyb.shardingjdbc.mapper.UserOrderMapper;
import io.shardingsphere.transaction.annotation.ShardingTransactionType;
import io.shardingsphere.transaction.api.TransactionType;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

@Service
public class UserOderService {
    @Autowired
    private UserMapper userMapper;

    @Autowired
    private UserOrderMapper userOrderMapper;

    // mybatis单独库的事务保证
    // @Transactional(rollbackFor = Exception.class)
    // 使用分布式事务 XA协议
    @ShardingTransactionType(TransactionType.XA)
    public int saveUserOrder(User user, UserOrder userOrder){
        userMapper.addUser(user);
        userOrder.setUser_id(user.getId());
        userOrderMapper.addOrder(userOrder);
        return 1;
    }
}

~~~

